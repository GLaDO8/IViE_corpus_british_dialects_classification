{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import python_speech_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.fftpack import dct\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data import\n",
    "def audio_import(nclass, naudio):\n",
    "    rate, data = wav.read('Read_Up/IDR' + str(nclass) + '/' + str(naudio) + '.wav')\n",
    "    filename = 'Data/IDR' + str(nclass) + '/' + str(naudio) + '.csv'\n",
    "    return rate, data, filename\n",
    "\n",
    "#parameters\n",
    "framelength, framestride, nfft, num_fbanks, n_cep_coeff, N = 0.025, 0.015, 512, 40, 12, 2\n",
    "\n",
    "#generate frames\n",
    "def frames_gen(rate, data, framelength, framestride):\n",
    "    frmlen, frmstrd, signallen = int(round(rate*framelength)), int(round(rate*framestride)), len(data)\n",
    "    paddinglen = frmstrd - (signallen - frmlen) % frmstrd #making number of frames even\n",
    "    paddedsig = np.concatenate((data, np.zeros(paddinglen)), axis = 0)\n",
    "    paddedsiglen = len(paddedsig)\n",
    "    nframes = int(np.floor((paddedsiglen - frmlen)/frmstrd) + 1)\n",
    "    indices = np.tile(np.arange(0, frmlen), (nframes, 1)) + np.tile((np.arange(0, nframes*frmstrd, frmstrd)), (frmlen, 1)).T\n",
    "    frames = paddedsig[indices]\n",
    "    return frames, frmlen\n",
    "\n",
    "#apply hamming window to each frame\n",
    "def hamming_window(frames, frmlen):\n",
    "    frames *= np.hamming(frmlen)\n",
    "    return frames\n",
    "\n",
    "#convert each windowed frame into a power spectrum\n",
    "def periodogram_gen(frames, nfft):\n",
    "    frame_fft = np.absolute(np.fft.rfft(frames, n = nfft, axis = 1))\n",
    "    frame_periodogram = np.square(frame_fft)/nfft\n",
    "    return frame_periodogram\n",
    "\n",
    "#helper functions\n",
    "def freq_to_mel(freq):\n",
    "    return 2595*np.log10(1+freq/700)\n",
    "def mel_to_freq(mel):\n",
    "    return 700*(np.power(10, mel/2595) - 1)\n",
    "\n",
    "# making mel-scale filterbank\n",
    "def filter_bank_gen(rate, num_fbanks, nfft):\n",
    "    #for x filter banks, we need x+2 mel points\n",
    "    low_mel_lim = 0\n",
    "    up_mel_lim = freq_to_mel(rate/2)\n",
    "    mel_range = np.linspace(0, up_mel_lim, num_fbanks + 2)\n",
    "    freq_range = mel_to_freq(mel_range)\n",
    "    bins = np.floor((nfft + 1) * freq_range/rate)\n",
    "    fbank = np.zeros((num_fbanks, int(np.floor(nfft/2 + 1))))\n",
    "    for m in range(1, num_fbanks + 1):\n",
    "        lower = int(bins[m - 1]) # lower\n",
    "        peak = int(bins[m]) # peak\n",
    "        upper = int(bins[m + 1]) # upper\n",
    "        for k in range(lower, peak):\n",
    "            fbank[m - 1, k] = (k - bins[m - 1])/(bins[m] - bins[m - 1])\n",
    "        for k in range(peak, upper):\n",
    "            fbank[m - 1, k] = (bins[m + 1] - k)/(bins[m + 1] - bins[m])\n",
    "    return fbank\n",
    "\n",
    "# filtered frames\n",
    "def filtered_frame_gen(frame_periodogram, fbank):\n",
    "    #multiply each frame with all filterbanks and add up for coefficients.\n",
    "    filter_banks = np.dot(frame_periodogram, fbank.T)\n",
    "    #for numerical stability\n",
    "    filter_banks = np.where(filter_banks == 0, np.finfo(float).eps, filter_banks) #if condition is true, return eps, else return original val\n",
    "    filter_banks = 20*np.log10(filter_banks)\n",
    "    return filter_banks\n",
    "\n",
    "#make mfcc coefficients\n",
    "def mfcc_gen(filter_banks, n_cep_coeff):\n",
    "    mfcc = dct(filter_banks, type = 2, axis = 1, norm = 'ortho')[:, 1:(n_cep_coeff + 1)]\n",
    "    return mfcc  \n",
    "\n",
    "#make delta and delta-delta coefficients\n",
    "def ctpn(n_cep_coeff, coeff_type, t, n):\n",
    "    if((t+n) > n_cep_coeff-1):\n",
    "        return coeff_type[:,n_cep_coeff-1]\n",
    "    elif(0 <= (t+n) <= n_cep_coeff-1):\n",
    "        return coeff_type[:, t+n]\n",
    "\n",
    "def ctmn(n_cep_coeff, coeff_type, t, n):\n",
    "    if((t-n) < 0):\n",
    "        return coeff_type[:,0]\n",
    "    elif(0 <= (t-n) <= n_cep_coeff-1):\n",
    "        return coeff_type[:, t-n]  \n",
    "    \n",
    "def deltacoeff(t, coeff_type):\n",
    "    dt = 0\n",
    "    for n in range(1,N):\n",
    "        dt+= n*(ctpn(n_cep_coeff, coeff_type, t, n) - ctmn(n_cep_coeff, coeff_type, t, n))/2*np.square(n)\n",
    "    return dt\n",
    "\n",
    "def deltacoeff_gen(coeff_type, n_cep_coeff):\n",
    "    deltacoef = np.zeros(coeff_type.shape)\n",
    "    for t in range(0, n_cep_coeff):\n",
    "        dt = deltacoeff(t, coeff_type)\n",
    "        deltacoef[:, t] = dt\n",
    "    return deltacoef\n",
    "\n",
    "def deltadeltacoeff_gen(deltacoef, n_cep_coeff):\n",
    "    deltadeltacoef = np.zeros(deltacoef.shape)\n",
    "    for t in range(0, n_cep_coeff):\n",
    "        ddt = deltacoeff(t, deltacoef)\n",
    "        deltadeltacoef[:, t] = ddt\n",
    "    return deltadeltacoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_data_gen(Data, framelength = framelength, framestride = framestride, nfft = nfft, num_fbanks = num_fbanks, n_cep_coeff = n_cep_coeff):\n",
    "    for nclass in range(1,10):\n",
    "        for naudio in range(1, 68):\n",
    "            #calculating mfcc\n",
    "            rate, data, filename = audio_import(nclass, naudio)\n",
    "            frames, frmlen = frames_gen(rate, data, framelength, framestride)\n",
    "            frames = hamming_window(frames, frmlen)\n",
    "            frame_periodogram = periodogram_gen(frames, nfft)\n",
    "            fbank = filter_bank_gen(rate, num_fbanks, nfft)\n",
    "            filter_banks = filtered_frame_gen(frame_periodogram, fbank)\n",
    "            mfcc = mfcc_gen(filter_banks, n_cep_coeff)\n",
    "            #calculating delta_coefficients \n",
    "#             mfcc = librosa.feature.mfcc(data.astype(float), sr = rate, n_mfcc=12).T\n",
    "#             mfcc = python_speech_features.base.mfcc(data, rate, winlen = 0.025, winstep = 0.015, nfilt = 40, nfft = 512, numcep = 12, preemph = 0)\n",
    "            mfcc = mfcc - np.mean(mfcc, axis = 0)\n",
    "            delta_coef = deltacoeff_gen(mfcc, n_cep_coeff)\n",
    "            deltadelta_coef = deltadeltacoeff_gen(delta_coef, n_cep_coeff)\n",
    "            print(mfcc.shape,nclass,naudio)\n",
    "#             Data = Data.append(pd.Series(np.hstack((np.mean(mfcc, axis = 0), np.mean(delta_coef, axis = 0), nclass))), ignore_index = True)\n",
    "            \n",
    "#     Data.columns = ['MFCC_mean' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_mean' + str(x) for x in range(0, n_cep_coeff)] + ['Dialect']\n",
    "#     return Data\n",
    "            Data = Data.append(pd.Series(np.hstack(\n",
    "                (np.mean(mfcc, axis = 0), np.max(mfcc, axis = 0), np.min(mfcc, axis = 0), np.std(mfcc, axis = 0), np.median(mfcc, axis = 0), skew(mfcc, axis = 0), \n",
    "                 np.mean(delta_coef, axis = 0), np.max(delta_coef, axis = 0), np.min(delta_coef, axis = 0), np.std(delta_coef, axis = 0), np.median(delta_coef, axis = 0), skew(delta_coef, axis = 0), \n",
    "                 np.mean(deltadelta_coef, axis = 0), np.max(deltadelta_coef, axis = 0), np.min(deltadelta_coef, axis = 0), np.std(deltadelta_coef, axis = 0), np.median(deltadelta_coef, axis = 0), skew(deltadelta_coef, axis = 0), nclass))), ignore_index = True)\n",
    "            \n",
    "    Data.columns = ['MFCC_mean' + str(x) for x in range(0, n_cep_coeff)] + ['MFCC_max' + str(x) for x in range(0, n_cep_coeff)] + ['MFCC_min' + str(x) for x in range(0, n_cep_coeff)] + ['MFCC_std' + str(x) for x in range(0, n_cep_coeff)] + ['MFCC_median' + str(x) for x in range(0, n_cep_coeff)] + ['MFCC_skew' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_mean' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_max' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_min' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_std' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_median' + str(x) for x in range(0, n_cep_coeff)] + ['DEL_skew' + str(x) for x in range(0, n_cep_coeff)] + ['DELDEL_mean' + str(x) for x in range(0, n_cep_coeff)] + ['DELDEL_max' + str(x) for x in range(0, n_cep_coeff)] + ['DELDEL_min' + str(x) for x in range(0, n_cep_coeff)] + ['DELDEL_std' + str(x) for x in range(0, n_cep_coeff)] + ['DELDEL_median' + str(x) for x in range(0, n_cep_coeff)] + ['DELDEL_skew' + str(x) for x in range(0, n_cep_coeff)] + ['Speaker']\n",
    "    return Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.DataFrame()\n",
    "Data = csv_data_gen(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, :-1], data.iloc[:,-1], test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_clf = LogisticRegression(\n",
    "#     random_state = 200,\n",
    "#     max_iter = 1000,\n",
    "#     verbose = 1,\n",
    "#     n_jobs = -1,\n",
    "#     solver = 'newton-cg'\n",
    "# )\n",
    "# lr_clf.fit(X_train, y_train)\n",
    "# predicted = lr_clf.predict_proba(X_test)\n",
    "\n",
    "# knn_clf = KNeighborsClassifier(\n",
    "#     n_neighbors = 5,\n",
    "#     n_jobs = -1,\n",
    "#     leaf_size = 100\n",
    "# )\n",
    "# knn_clf.fit(X_train, y_train)\n",
    "# predicted = knn_clf.predict_proba(X_test)\n",
    "\n",
    "# svc_clf = svm.SVC(\n",
    "#     kernel = 'linear',\n",
    "#     verbose = True,\n",
    "#     random_state = True\n",
    "# )\n",
    "# svc_clf.fit(X_train, y_train)\n",
    "# pred_labels = svc_clf.predict(X_test)\n",
    "\n",
    "clf = svm.SVC(kernel = 'linear', probability=True, C = 10, gamma = 0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(clf.predict(X_test), y_test))\n",
    "# C_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "# gamma_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "# param_grid = {'C': C_grid, 'gamma' : gamma_grid}\n",
    "\n",
    "# grid = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv = 3, scoring = \"accuracy\")\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# # Find the best model\n",
    "# print(grid.best_score_)\n",
    "\n",
    "# print(grid.best_params_)\n",
    "\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = predicted.argmax(axis = 1)\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((\"Accuracy score\")+str(accuracy_score(y_test, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
